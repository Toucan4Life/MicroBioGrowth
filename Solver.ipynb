{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "#Load file\n",
    "dataframe = pd.read_csv(\"data.csv\", delimiter=\";\")\n",
    "\n",
    "print(f\"We got {len(dataframe)} rows and {len(dataframe.columns)} columns\")\n",
    "\n",
    "#Extract Data\n",
    "features = pd.DataFrame()\n",
    "\n",
    "dataframe.loc[dataframe['CRP    '].str.startswith('<'),'CRP    ']=0\n",
    "dataframe=dataframe.iloc[:,[2,4,6,8,10,12,14,16,18,21,24,26,28,30,33,35,37,41,42,43]]\n",
    "#Treat string data as NaN\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "for col in dataframe:\n",
    "    dataframe[col]=pd.to_numeric(dataframe[col], errors='coerce') \n",
    "\n",
    "#Replace NaN by mean value\n",
    "imp = SimpleImputer(missing_values=pd.NA, strategy='median')\n",
    "dataframe=pd.DataFrame(imp.fit_transform(dataframe))\n",
    "features['GB'] = 1 / (1 + np.exp(-(dataframe.iloc[:,0] - 10)))\n",
    "features['GR'] = 1 / (1 + np.exp(-(dataframe.iloc[:,1] - 10)))\n",
    "features['Epi'] = 1 / (1 + np.exp(-(dataframe.iloc[:,2] - 5)))\n",
    "features['Nepi'] = 1 / (1 + np.exp(-(dataframe.iloc[:,3] - 5)))\n",
    "features['Levure'] = 1 / (1 + np.exp(-(dataframe.iloc[:,4] - 10)))\n",
    "features['Bacterie'] = 1 / (1 + np.exp(-(dataframe.iloc[:,5] - 148)))\n",
    "features['CylH'] = 1 / (1 + np.exp(-(dataframe.iloc[:,6] - 5)))\n",
    "features['CylP'] = 1 / (1 + np.exp(-(dataframe.iloc[:,7] - 3)))\n",
    "features['Crystaux'] = 1 / (1 + np.exp(-(dataframe.iloc[:,8] - 3)))\n",
    "features['ERY'] = dataframe.iloc[:,9]\n",
    "features['LEU'] = dataframe.iloc[:,10]\n",
    "features['NIT'] = 1 / (1 + np.exp(-(dataframe.iloc[:,11] - 60.2)))\n",
    "features['KET'] = dataframe.iloc[:,12]\n",
    "features['GLU'] = dataframe.iloc[:,13]\n",
    "features['PRO'] = dataframe.iloc[:,14]\n",
    "features['Prote'] = dataframe.iloc[:,15]\n",
    "features['PH'] = dataframe.iloc[:,16]\n",
    "features['SG'] = dataframe.iloc[:,17]\n",
    "features['CRP'] = dataframe.iloc[:,18]\n",
    "features['target'] = dataframe.iloc[:,19]\n",
    "scaledFeatures = pd.DataFrame(preprocessing.scale(features),columns = features.columns)\n",
    "features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection technique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem space has >10 dimensions, we fall into https://en.wikipedia.org/wiki/Curse_of_dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to see the matrix of correlation\n",
    "import seaborn as sns\n",
    "\t\t     \n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(features.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "v_Treshold = VarianceThreshold(threshold=0.01)\n",
    "v_Treshold.fit(features)\n",
    "v_Treshold.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.svm import LinearSVC\n",
    "# We chose linear SVC for this reason : https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "ffs = SequentialFeatureSelector(LinearSVC(max_iter=10000), n_features_to_select=8)\n",
    "ffs.fit(scaledFeatures.iloc[:, 0:19].values,features.iloc[:,19].values.ravel())\n",
    "ffs.get_support(indices=True)\n",
    "reducedFeatures = scaledFeatures.iloc[:, ffs.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian model below, but less effective\n",
    "\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# from sklearn.naive_bayes  import GaussianNB\n",
    "\n",
    "# ffs = SequentialFeatureSelector(GaussianNB(), n_features_to_select=2)\n",
    "# ffs.fit(features.iloc[:, 0:19].values,features.iloc[:,19].values.ravel())\n",
    "# ffs.get_support(indices=True)\n",
    "#reducedFeatures = features.iloc[:, ffs.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExhaustiveFeatureSelector, but take an eternity\n",
    "\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "efs=ExhaustiveFeatureSelector(LinearSVC(max_iter=10000),min_features=1, max_features=2)\n",
    "efs = efs.fit(scaledFeatures.iloc[:, 0:19], features.iloc[:,19].values.ravel())\n",
    "efs.best_score_\n",
    "efs.best_idx_\n",
    "efs.best_feature_names_\n",
    "df = pd.DataFrame.from_dict(efs.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "\n",
    "reducedFeaturesForPlot = features.iloc[:, list(efs.best_idx_)]\n",
    "reducedFeaturesForPlot['target'] = features.iloc[:,19]\n",
    "#plot the first 2 principals components\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot() \n",
    "ax.set_xlabel('LEU', fontsize = 15)\n",
    "ax.set_ylabel('PH TARGET', fontsize = 15)\n",
    "ax.set_title('Classification', fontsize = 20)\n",
    "\n",
    "cond = reducedFeaturesForPlot['target'] == 0\n",
    "\n",
    "subset_a = reducedFeaturesForPlot[cond]\n",
    "subset_b = reducedFeaturesForPlot[~cond]\n",
    "plt.scatter(subset_a.iloc[:,0], subset_a.iloc[:,1], s=60, c='b', label='Sterile')\n",
    "plt.scatter(subset_b.iloc[:,0], subset_b.iloc[:,1], s=60, c='r', label='Infected') \n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try to classify anyway, using https://medium.com/thrive-in-ai/classification-algorithms-in-python-5f58a7a27b88\n",
    "#https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(reducedFeatures, features.iloc[:,19], test_size=0.2)\n",
    "lr_clf = LinearSVC(max_iter=10000).fit(X_train,Y_train.values.ravel())\n",
    "lr_clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes  import GaussianNB\n",
    "\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(reducedFeatures, features.iloc[:,19], test_size=0.2)\n",
    "lr_clf = GaussianNB().fit(X_train,Y_train.values.ravel())\n",
    "lr_clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "# X_train, X_test, Y_train,Y_test = train_test_split(features.iloc[:,0:19], features.iloc[:,19], test_size=0.2)\n",
    "# lr_clf = tree.DecisionTreeClassifier().fit(preprocessing.scale(X_train),Y_train.values.ravel())\n",
    "# lr_clf.score(X_test,Y_test)\n",
    "# plt.figure(figsize=(18,18))\n",
    "# tree.plot_tree(lr_clf, feature_names=features.iloc[:,0:19].columns, fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's find the most relevant dimension using PCA\n",
    "\n",
    "#We first need to normalize the data\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "principalComponents = pca.fit_transform(scaledFeatures)\n",
    "\n",
    "print (f\"percentage of precision with the number of components :\\n {pca.explained_variance_ratio_.cumsum()}\")\n",
    "\n",
    "#relationship from data to component\n",
    "#print(pd.DataFrame(pca.components_,columns=x.columns))\n",
    "principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "finalDf = pd.concat([principalDf, features.iloc[:,19]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the first 2 principals components\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot() \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "cond = finalDf.iloc[:,-1:] == 0\n",
    "cond = cond.squeeze()\n",
    "subset_a = finalDf[cond.squeeze()]\n",
    "subset_b = finalDf[~cond]\n",
    "plt.scatter(subset_a.iloc[:,1], subset_a.iloc[:,2], s=60, c='b', label='Sterile')\n",
    "plt.scatter(subset_b.iloc[:,1], subset_b.iloc[:,2], s=60, c='r', label='Infected') \n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
